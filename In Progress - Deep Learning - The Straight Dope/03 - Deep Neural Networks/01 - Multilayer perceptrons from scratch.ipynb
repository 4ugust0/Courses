{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Multilayer perceptrons from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\tests\\old\\test_attrs_data.py:251: DeprecationWarning: invalid escape sequence \\H\n",
      "  s = b\"Hello\\x00\\Hello\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\func_inspect.py:53: DeprecationWarning: invalid escape sequence \\<\n",
      "  '\\<doctest (.*\\.rst)\\[(.*)\\]\\>', source_file).groups()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_memory_helpers.py:10: DeprecationWarning: invalid escape sequence \\s\n",
      "  cookie_re = re.compile(\"coding[:=]\\s*([-\\w.]+)\")\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from mxnet import gluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ctx = mx.cpu()\n",
    "model_ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "batch_size = 64\n",
    "num_examples = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data pre-processing\n",
    "def transform(data, label):\n",
    "    return data.astype(np.float32) / 255, label.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gluon.data.DataLoader(gluon.data.vision.MNIST(train=True, transform=transform),\n",
    "                                   batch_size,\n",
    "                                   shuffle=True)\n",
    "test_data = gluon.data.DataLoader(gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                  batch_size,\n",
    "                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = 256\n",
    "weight_scale = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#  Allocate parameters for the first hidden layer\n",
    "#######################\n",
    "W1 = mx.nd.random_normal(shape=(num_inputs, num_hidden),\n",
    "                         scale=weight_scale,\n",
    "                         ctx=model_ctx)\n",
    "b1 = mx.nd.random_normal(shape=num_hidden,\n",
    "                         scale=weight_scale,\n",
    "                         ctx=model_ctx)\n",
    "\n",
    "#######################\n",
    "#  Allocate parameters for the second hidden layer\n",
    "#######################\n",
    "W2 = mx.nd.random_normal(shape=(num_hidden, num_hidden),\n",
    "                         scale=weight_scale,\n",
    "                         ctx=model_ctx)\n",
    "b2 = mx.nd.random_normal(shape=num_hidden, \n",
    "                         scale=weight_scale, \n",
    "                         ctx=model_ctx)\n",
    "\n",
    "#######################\n",
    "#  Allocate parameters for the output layer\n",
    "#######################\n",
    "W3 = mx.nd.random_normal(shape=(num_hidden, num_outputs),\n",
    "                         scale=weight_scale,\n",
    "                         ctx=model_ctx)\n",
    "b3 = mx.nd.random_normal(shape=num_outputs,\n",
    "                         scale=weight_scale,\n",
    "                         ctx=model_ctx)\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attaching gradients\n",
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU\n",
    "def relu(X):\n",
    "    return mx.nd.maximum(X, mx.nd.zeros_like(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax\n",
    "def softmax(y_linear):\n",
    "    exp = mx.nd.exp(y_linear - mx.nd.max(y_linear))\n",
    "    partition = mx.nd.nansum(data=exp,\n",
    "                             axis=0,\n",
    "                             exclude=True).reshape((-1, 1))\n",
    "    return exp / partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(yhat, y):\n",
    "    return - mx.nd.nansum(data=(y * mx.nd.log(yhat)),\n",
    "                          axis=0,\n",
    "                          exclude=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy(yhat_linear, y):\n",
    "    return - mx.nd.nansum(y * mx.nd.log_softmax(yhat_linear),\n",
    "                          axis=0,\n",
    "                          exclude=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    #######################\n",
    "    #  Compute the first hidden layer\n",
    "    #######################\n",
    "    h1_linear = mx.nd.dot(X, W1) + b1\n",
    "    h1 = relu(h1_linear)\n",
    "\n",
    "    #######################\n",
    "    #  Compute the second hidden layer\n",
    "    #######################\n",
    "    h2_linear = mx.nd.dot(h1, W2) + b2\n",
    "    h2 = relu(h2_linear)\n",
    "\n",
    "    #######################\n",
    "    #  Compute the output layer.\n",
    "    #  We will omit the softmax function here\n",
    "    #  because it will be applied\n",
    "    #  in the softmax_cross_entropy loss\n",
    "    #######################\n",
    "    yhat_linear = mx.nd.dot(h2, W3) + b3\n",
    "    return yhat_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(model_ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(model_ctx)\n",
    "        output = net(data)\n",
    "        predictions = mx.nd.argmax(output, axis=1)\n",
    "        numerator += mx.nd.sum(predictions == label)\n",
    "        denominator += data.shape[0]\n",
    "    return (numerator / denominator).asscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = .001\n",
    "smoothing_constant = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                      | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 1.241500595998764, Train_acc 0.8836167, Test_acc 0.8843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█████████████████▍                                                                                                                                                            | 1/10 [00:18<02:44, 18.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Loss: 0.33498516895771024, Train_acc 0.9244, Test_acc 0.9256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████████████████████████▊                                                                                                                                           | 2/10 [00:41<02:45, 20.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2. Loss: 0.22894775596062342, Train_acc 0.9464833, Test_acc 0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████████████████████████████████▏                                                                                                                         | 3/10 [01:05<02:33, 21.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3. Loss: 0.16448531580368678, Train_acc 0.96243334, Test_acc 0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████████████████████████████████████████▌                                                                                                        | 4/10 [01:30<02:15, 22.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4. Loss: 0.127963012166818, Train_acc 0.9690167, Test_acc 0.9643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████████████████████████████████████████████████████                                                                                       | 5/10 [01:54<01:54, 22.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5. Loss: 0.10466508792390426, Train_acc 0.9759, Test_acc 0.9689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 6/10 [02:19<01:32, 23.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6. Loss: 0.08728616865972678, Train_acc 0.9795833, Test_acc 0.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 7/10 [02:46<01:11, 23.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7. Loss: 0.07480254614502191, Train_acc 0.9827333, Test_acc 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 8/10 [03:10<00:47, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8. Loss: 0.06456454908301433, Train_acc 0.9848667, Test_acc 0.9744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 9/10 [03:34<00:23, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9. Loss: 0.05640946247726679, Train_acc 0.98445, Test_acc 0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:59<00:00, 23.98s/it]\n"
     ]
    }
   ],
   "source": [
    "for e in tqdm(range(epochs)):\n",
    "    cumulative_loss = 0\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(model_ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(model_ctx)\n",
    "        label_one_hot = mx.nd.one_hot(label, 10)\n",
    "        with mx.autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label_one_hot)\n",
    "        loss.backward()\n",
    "        SGD(params, learning_rate)\n",
    "        cumulative_loss += mx.nd.sum(loss).asscalar()\n",
    "\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" %\n",
    "          (e, cumulative_loss/num_examples, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to do prediction\n",
    "def model_predict(net,data):\n",
    "    output = net(data)\n",
    "    return mx.nd.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions are: \n",
      "[7. 1. 5. 3. 2. 6. 5. 2. 6. 9.]\n",
      "<NDArray 10 @cpu(0)>\n",
      "true labels : \n",
      "[7. 1. 5. 3. 2. 6. 5. 2. 6. 9.]\n",
      "<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# let's sample 10 random data points from the test set\n",
    "sample_data = gluon.data.DataLoader(dataset=gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                    batch_size = samples, shuffle=True)\n",
    "for i, (data, label) in enumerate(sample_data):\n",
    "    data = data.as_in_context(model_ctx)\n",
    "    im = mx.nd.transpose(data,(1, 0, 2, 3))\n",
    "    im = mx.nd.reshape(im,(28, 10*28, 1))\n",
    "    imtiles = mx.nd.tile(im, (1, 1, 3))\n",
    "\n",
    "    plt.imshow(imtiles.asnumpy())\n",
    "    plt.show()\n",
    "    pred=model_predict(net,data.reshape((-1, 784)))\n",
    "    print('model predictions are:', pred)\n",
    "    print('true labels :', label)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
