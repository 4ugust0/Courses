{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6.1.2 - Using word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding layer with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "# Number of maximum tokens is equal of maximum word index + 1\n",
    "max_number_of_tokens = 1000\n",
    "embedding_dimentionality = 64\n",
    "embedding_layer = Embedding(max_number_of_tokens, embedding_dimentionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers transforms a 2D input tensor of integer of shape (number_of samples, sequence_length) into a 3D floating point tensor, of shape (number_of_samples, sequence_length, embedding_dimensionality.)\n",
    "Such tensor can be processed a RNN layer of a 1D convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of words considered as features\n",
    "max_features = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cutting reviews after only 20 words\n",
    "sequence_max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_sequence = pad_sequences(x_train, maxlen = sequence_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].__getitem__(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,\n",
       "        113,  103,   32,   15,   16, 5345,   19,  178,   32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sequence[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,\n",
       "        113,  103,   32,   15,   16, 5345,   19,  178,   32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  23,    4, 1690,   15,   16,    4, 1355,    5,   28,    6,   52,\n",
       "        154,  462,   33,   89,   78,  285,   16,  145,   95])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sequence[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = max_features, output_dim = 8, input_length = sequence_max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer = 'rmsprop', \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 6s 307us/step - loss: 0.6759 - acc: 0.6050 - val_loss: 0.6398 - val_acc: 0.6814\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 4s 191us/step - loss: 0.5657 - acc: 0.7427 - val_loss: 0.5467 - val_acc: 0.7206\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 4s 187us/step - loss: 0.4752 - acc: 0.7808 - val_loss: 0.5113 - val_acc: 0.7384\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 4s 203us/step - loss: 0.4263 - acc: 0.8077 - val_loss: 0.5008 - val_acc: 0.7452\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 4s 221us/step - loss: 0.3930 - acc: 0.8258 - val_loss: 0.4981 - val_acc: 0.7538\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.3668 - acc: 0.8395 - val_loss: 0.5014 - val_acc: 0.7530\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 4s 207us/step - loss: 0.3435 - acc: 0.8533 - val_loss: 0.5052 - val_acc: 0.7520\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 4s 199us/step - loss: 0.3223 - acc: 0.8657 - val_loss: 0.5132 - val_acc: 0.7486\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 4s 192us/step - loss: 0.3022 - acc: 0.8766 - val_loss: 0.5213 - val_acc: 0.7490\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 4s 185us/step - loss: 0.2839 - acc: 0.8860 - val_loss: 0.5303 - val_acc: 0.7466\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "history = model.fit(x = x_train_sequence, \n",
    "                    y = y_train, \n",
    "                    epochs = 10, \n",
    "                    batch_size = 32, \n",
    "                    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be downloaded from: http://mng.bz/0tIo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_dir = './data/Chapter 6.1.2 - Using word embeddings/aclImdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(imdb_dir, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        # Taking into consideration files which are only .txt\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding=\"utf8\")\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using only first 100 words of each review\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of training samples\n",
    "training_samples = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of validation samples\n",
    "validation_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenizing only top 10 000 words in the dataset.\n",
    "max_words = 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing Tokenizer\n",
    "tokenizer = Tokenizer(num_words = max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitting the Tokenizer on the text\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text to sequence\n",
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[62,\n",
       "  4,\n",
       "  3,\n",
       "  129,\n",
       "  34,\n",
       "  44,\n",
       "  7576,\n",
       "  1414,\n",
       "  15,\n",
       "  3,\n",
       "  4252,\n",
       "  514,\n",
       "  43,\n",
       "  16,\n",
       "  3,\n",
       "  633,\n",
       "  133,\n",
       "  12,\n",
       "  6,\n",
       "  3,\n",
       "  1301,\n",
       "  459,\n",
       "  4,\n",
       "  1751,\n",
       "  209,\n",
       "  3,\n",
       "  7693,\n",
       "  308,\n",
       "  6,\n",
       "  676,\n",
       "  80,\n",
       "  32,\n",
       "  2137,\n",
       "  1110,\n",
       "  3008,\n",
       "  31,\n",
       "  1,\n",
       "  929,\n",
       "  4,\n",
       "  42,\n",
       "  5120,\n",
       "  469,\n",
       "  9,\n",
       "  2665,\n",
       "  1751,\n",
       "  1,\n",
       "  223,\n",
       "  55,\n",
       "  16,\n",
       "  54,\n",
       "  828,\n",
       "  1318,\n",
       "  847,\n",
       "  228,\n",
       "  9,\n",
       "  40,\n",
       "  96,\n",
       "  122,\n",
       "  1484,\n",
       "  57,\n",
       "  145,\n",
       "  36,\n",
       "  1,\n",
       "  996,\n",
       "  141,\n",
       "  27,\n",
       "  676,\n",
       "  122,\n",
       "  1,\n",
       "  411,\n",
       "  59,\n",
       "  94,\n",
       "  2278,\n",
       "  303,\n",
       "  772,\n",
       "  5,\n",
       "  3,\n",
       "  837,\n",
       "  20,\n",
       "  3,\n",
       "  1755,\n",
       "  646,\n",
       "  42,\n",
       "  125,\n",
       "  71,\n",
       "  22,\n",
       "  235,\n",
       "  101,\n",
       "  16,\n",
       "  46,\n",
       "  49,\n",
       "  624,\n",
       "  31,\n",
       "  702,\n",
       "  84,\n",
       "  702,\n",
       "  378,\n",
       "  3493,\n",
       "  2,\n",
       "  8422,\n",
       "  67,\n",
       "  27,\n",
       "  107,\n",
       "  3348],\n",
       " [4517,\n",
       "  514,\n",
       "  14,\n",
       "  3,\n",
       "  3417,\n",
       "  159,\n",
       "  8595,\n",
       "  1702,\n",
       "  6,\n",
       "  4892,\n",
       "  53,\n",
       "  16,\n",
       "  4518,\n",
       "  5674,\n",
       "  138,\n",
       "  5,\n",
       "  1023,\n",
       "  4988,\n",
       "  3050,\n",
       "  4519,\n",
       "  588,\n",
       "  1339,\n",
       "  34,\n",
       "  6,\n",
       "  1544,\n",
       "  95,\n",
       "  3,\n",
       "  758,\n",
       "  4,\n",
       "  5,\n",
       "  24,\n",
       "  3513,\n",
       "  8,\n",
       "  4,\n",
       "  9,\n",
       "  109,\n",
       "  3051,\n",
       "  5,\n",
       "  1,\n",
       "  1067,\n",
       "  14,\n",
       "  3,\n",
       "  4520,\n",
       "  79,\n",
       "  20,\n",
       "  2086,\n",
       "  6,\n",
       "  4519,\n",
       "  574,\n",
       "  2798,\n",
       "  7262,\n",
       "  38,\n",
       "  489,\n",
       "  1,\n",
       "  8595,\n",
       "  301,\n",
       "  122,\n",
       "  14,\n",
       "  4253,\n",
       "  18,\n",
       "  1693,\n",
       "  942,\n",
       "  1,\n",
       "  1702,\n",
       "  6,\n",
       "  6538,\n",
       "  31,\n",
       "  1,\n",
       "  998,\n",
       "  1807,\n",
       "  667,\n",
       "  24,\n",
       "  104,\n",
       "  2602,\n",
       "  485,\n",
       "  34,\n",
       "  3285,\n",
       "  1,\n",
       "  6539,\n",
       "  1048,\n",
       "  43,\n",
       "  16,\n",
       "  2753,\n",
       "  2547,\n",
       "  33,\n",
       "  1340,\n",
       "  5,\n",
       "  2103,\n",
       "  1,\n",
       "  4518,\n",
       "  1537,\n",
       "  20,\n",
       "  3,\n",
       "  1702,\n",
       "  3249,\n",
       "  20,\n",
       "  32,\n",
       "  4348,\n",
       "  1105,\n",
       "  18,\n",
       "  134,\n",
       "  228,\n",
       "  24,\n",
       "  4760,\n",
       "  217,\n",
       "  1927,\n",
       "  32,\n",
       "  3230,\n",
       "  8,\n",
       "  1,\n",
       "  4676,\n",
       "  1975,\n",
       "  1135,\n",
       "  4,\n",
       "  1,\n",
       "  1702,\n",
       "  5675,\n",
       "  9,\n",
       "  6627,\n",
       "  80,\n",
       "  1,\n",
       "  2016,\n",
       "  118,\n",
       "  9,\n",
       "  8169,\n",
       "  5,\n",
       "  1,\n",
       "  1321,\n",
       "  205,\n",
       "  4010,\n",
       "  8,\n",
       "  1,\n",
       "  652,\n",
       "  4,\n",
       "  1,\n",
       "  5924,\n",
       "  16,\n",
       "  942,\n",
       "  8,\n",
       "  343,\n",
       "  6259,\n",
       "  1090,\n",
       "  8,\n",
       "  257,\n",
       "  117,\n",
       "  6260,\n",
       "  2058,\n",
       "  122,\n",
       "  261,\n",
       "  1,\n",
       "  709,\n",
       "  15,\n",
       "  1,\n",
       "  14,\n",
       "  33,\n",
       "  335,\n",
       "  16,\n",
       "  55,\n",
       "  699,\n",
       "  617,\n",
       "  43,\n",
       "  7,\n",
       "  7,\n",
       "  79,\n",
       "  570,\n",
       "  463,\n",
       "  1,\n",
       "  1072,\n",
       "  272,\n",
       "  4517,\n",
       "  6041,\n",
       "  11,\n",
       "  330,\n",
       "  751,\n",
       "  5,\n",
       "  1,\n",
       "  6792,\n",
       "  566,\n",
       "  1685,\n",
       "  705,\n",
       "  4517,\n",
       "  5456,\n",
       "  13,\n",
       "  523,\n",
       "  31,\n",
       "  1513,\n",
       "  9878,\n",
       "  134,\n",
       "  277,\n",
       "  171,\n",
       "  37,\n",
       "  42,\n",
       "  8288,\n",
       "  10,\n",
       "  188,\n",
       "  132,\n",
       "  4517,\n",
       "  6,\n",
       "  98,\n",
       "  429,\n",
       "  4,\n",
       "  1547,\n",
       "  353,\n",
       "  9,\n",
       "  6,\n",
       "  438,\n",
       "  258,\n",
       "  21,\n",
       "  2696,\n",
       "  15,\n",
       "  1,\n",
       "  205,\n",
       "  1003,\n",
       "  43,\n",
       "  4,\n",
       "  1,\n",
       "  286,\n",
       "  4517,\n",
       "  105,\n",
       "  10,\n",
       "  25,\n",
       "  107,\n",
       "  35,\n",
       "  227,\n",
       "  10,\n",
       "  162,\n",
       "  420,\n",
       "  11,\n",
       "  28,\n",
       "  1,\n",
       "  115,\n",
       "  40,\n",
       "  9,\n",
       "  44,\n",
       "  58,\n",
       "  1636,\n",
       "  111,\n",
       "  4,\n",
       "  1,\n",
       "  286,\n",
       "  16,\n",
       "  3,\n",
       "  324,\n",
       "  1693,\n",
       "  942,\n",
       "  6538,\n",
       "  92,\n",
       "  1,\n",
       "  6627,\n",
       "  158,\n",
       "  26,\n",
       "  64,\n",
       "  1,\n",
       "  3230,\n",
       "  6261,\n",
       "  4,\n",
       "  1,\n",
       "  276,\n",
       "  1,\n",
       "  1184,\n",
       "  68,\n",
       "  266,\n",
       "  5,\n",
       "  1656,\n",
       "  1,\n",
       "  201,\n",
       "  4517,\n",
       "  16,\n",
       "  157,\n",
       "  1059,\n",
       "  1685,\n",
       "  506,\n",
       "  4,\n",
       "  1,\n",
       "  807,\n",
       "  1,\n",
       "  1150,\n",
       "  4483,\n",
       "  6,\n",
       "  118,\n",
       "  9,\n",
       "  2665,\n",
       "  363,\n",
       "  1,\n",
       "  127,\n",
       "  16,\n",
       "  3,\n",
       "  5283,\n",
       "  6540,\n",
       "  4416,\n",
       "  145,\n",
       "  2603,\n",
       "  1001,\n",
       "  342,\n",
       "  51,\n",
       "  1,\n",
       "  942,\n",
       "  1126,\n",
       "  43,\n",
       "  39,\n",
       "  14,\n",
       "  1,\n",
       "  39,\n",
       "  45,\n",
       "  98,\n",
       "  4,\n",
       "  1,\n",
       "  3584,\n",
       "  23,\n",
       "  3051,\n",
       "  42,\n",
       "  3,\n",
       "  539,\n",
       "  323,\n",
       "  12,\n",
       "  97,\n",
       "  25,\n",
       "  90,\n",
       "  15,\n",
       "  3,\n",
       "  84,\n",
       "  114,\n",
       "  1685,\n",
       "  506,\n",
       "  18,\n",
       "  75,\n",
       "  6887,\n",
       "  1727,\n",
       "  750,\n",
       "  411,\n",
       "  267,\n",
       "  1322,\n",
       "  3,\n",
       "  144,\n",
       "  580,\n",
       "  4,\n",
       "  2373,\n",
       "  39,\n",
       "  833,\n",
       "  39,\n",
       "  1071,\n",
       "  814,\n",
       "  11,\n",
       "  6,\n",
       "  3,\n",
       "  1045,\n",
       "  1429,\n",
       "  134,\n",
       "  1,\n",
       "  244,\n",
       "  111,\n",
       "  938,\n",
       "  28,\n",
       "  2161,\n",
       "  15,\n",
       "  1028,\n",
       "  231,\n",
       "  21,\n",
       "  12,\n",
       "  73,\n",
       "  567,\n",
       "  100,\n",
       "  1,\n",
       "  1702,\n",
       "  8169,\n",
       "  222,\n",
       "  21,\n",
       "  14,\n",
       "  73,\n",
       "  8926,\n",
       "  14,\n",
       "  10,\n",
       "  194,\n",
       "  47,\n",
       "  141,\n",
       "  25,\n",
       "  74,\n",
       "  57,\n",
       "  51,\n",
       "  1,\n",
       "  3022,\n",
       "  410,\n",
       "  571,\n",
       "  180,\n",
       "  89,\n",
       "  1257,\n",
       "  53,\n",
       "  12,\n",
       "  73,\n",
       "  16,\n",
       "  3,\n",
       "  168,\n",
       "  659,\n",
       "  4,\n",
       "  663,\n",
       "  5121,\n",
       "  1544,\n",
       "  41,\n",
       "  18,\n",
       "  222,\n",
       "  40,\n",
       "  139,\n",
       "  1883,\n",
       "  130,\n",
       "  739,\n",
       "  4201,\n",
       "  14,\n",
       "  1,\n",
       "  3494,\n",
       "  911,\n",
       "  6,\n",
       "  142,\n",
       "  18,\n",
       "  61,\n",
       "  211,\n",
       "  3,\n",
       "  375,\n",
       "  4,\n",
       "  136,\n",
       "  1196,\n",
       "  57,\n",
       "  555,\n",
       "  229,\n",
       "  5,\n",
       "  40,\n",
       "  165,\n",
       "  3765,\n",
       "  8,\n",
       "  1,\n",
       "  972,\n",
       "  7,\n",
       "  7,\n",
       "  1,\n",
       "  341,\n",
       "  371,\n",
       "  2246,\n",
       "  307,\n",
       "  4,\n",
       "  4517,\n",
       "  518,\n",
       "  231,\n",
       "  134,\n",
       "  1,\n",
       "  175,\n",
       "  245,\n",
       "  2052,\n",
       "  759,\n",
       "  32,\n",
       "  1724,\n",
       "  531,\n",
       "  4,\n",
       "  926,\n",
       "  583,\n",
       "  3,\n",
       "  159,\n",
       "  633,\n",
       "  894,\n",
       "  717,\n",
       "  108,\n",
       "  50,\n",
       "  136,\n",
       "  16,\n",
       "  739,\n",
       "  4201,\n",
       "  14,\n",
       "  2178,\n",
       "  5,\n",
       "  2104,\n",
       "  43,\n",
       "  1727,\n",
       "  1203,\n",
       "  2225,\n",
       "  136,\n",
       "  1,\n",
       "  3789,\n",
       "  39,\n",
       "  157,\n",
       "  375,\n",
       "  4,\n",
       "  348,\n",
       "  2345,\n",
       "  583,\n",
       "  1,\n",
       "  134,\n",
       "  10,\n",
       "  59,\n",
       "  37,\n",
       "  5,\n",
       "  64,\n",
       "  11,\n",
       "  1724,\n",
       "  926,\n",
       "  10,\n",
       "  241,\n",
       "  21,\n",
       "  249,\n",
       "  10,\n",
       "  97,\n",
       "  866,\n",
       "  140,\n",
       "  3,\n",
       "  747,\n",
       "  286,\n",
       "  531,\n",
       "  602,\n",
       "  4,\n",
       "  4517,\n",
       "  14,\n",
       "  870,\n",
       "  1,\n",
       "  19,\n",
       "  44,\n",
       "  1957,\n",
       "  906,\n",
       "  16,\n",
       "  524,\n",
       "  8058,\n",
       "  7476,\n",
       "  1588,\n",
       "  2823,\n",
       "  10,\n",
       "  77,\n",
       "  132,\n",
       "  54,\n",
       "  50,\n",
       "  82,\n",
       "  71,\n",
       "  1,\n",
       "  2876,\n",
       "  1702,\n",
       "  2179,\n",
       "  299,\n",
       "  710,\n",
       "  84,\n",
       "  342,\n",
       "  364,\n",
       "  16,\n",
       "  1,\n",
       "  82,\n",
       "  104,\n",
       "  4517,\n",
       "  2279,\n",
       "  11,\n",
       "  301,\n",
       "  3108,\n",
       "  4,\n",
       "  270,\n",
       "  8,\n",
       "  1,\n",
       "  2365,\n",
       "  4,\n",
       "  899,\n",
       "  258,\n",
       "  10,\n",
       "  67,\n",
       "  101,\n",
       "  4,\n",
       "  773,\n",
       "  4,\n",
       "  430,\n",
       "  105,\n",
       "  71,\n",
       "  11,\n",
       "  35,\n",
       "  10,\n",
       "  195,\n",
       "  3,\n",
       "  114,\n",
       "  2485,\n",
       "  1,\n",
       "  202,\n",
       "  136,\n",
       "  23,\n",
       "  3,\n",
       "  114,\n",
       "  750,\n",
       "  469,\n",
       "  1,\n",
       "  1060,\n",
       "  6,\n",
       "  547,\n",
       "  21,\n",
       "  73,\n",
       "  2315,\n",
       "  39,\n",
       "  1071,\n",
       "  6,\n",
       "  4844,\n",
       "  60,\n",
       "  6,\n",
       "  3,\n",
       "  899,\n",
       "  14,\n",
       "  10,\n",
       "  11,\n",
       "  97,\n",
       "  25,\n",
       "  74,\n",
       "  3,\n",
       "  181,\n",
       "  49,\n",
       "  19,\n",
       "  45,\n",
       "  90,\n",
       "  2877,\n",
       "  7,\n",
       "  7,\n",
       "  1,\n",
       "  362,\n",
       "  1230,\n",
       "  23,\n",
       "  2652,\n",
       "  45,\n",
       "  161,\n",
       "  2087,\n",
       "  1,\n",
       "  113,\n",
       "  215,\n",
       "  84,\n",
       "  104,\n",
       "  55,\n",
       "  731,\n",
       "  2280,\n",
       "  714,\n",
       "  4311,\n",
       "  44,\n",
       "  298,\n",
       "  234,\n",
       "  9,\n",
       "  13,\n",
       "  3,\n",
       "  1319,\n",
       "  5,\n",
       "  320,\n",
       "  8,\n",
       "  11,\n",
       "  28,\n",
       "  55,\n",
       "  731,\n",
       "  2280,\n",
       "  588,\n",
       "  1339,\n",
       "  269,\n",
       "  151,\n",
       "  79,\n",
       "  28,\n",
       "  55,\n",
       "  731,\n",
       "  2280,\n",
       "  844,\n",
       "  2105,\n",
       "  269,\n",
       "  1816,\n",
       "  134,\n",
       "  2682,\n",
       "  1365,\n",
       "  844,\n",
       "  6,\n",
       "  345,\n",
       "  114,\n",
       "  5,\n",
       "  78,\n",
       "  47,\n",
       "  23,\n",
       "  955,\n",
       "  4,\n",
       "  82,\n",
       "  1076,\n",
       "  1586,\n",
       "  5,\n",
       "  165,\n",
       "  43,\n",
       "  15,\n",
       "  96,\n",
       "  7,\n",
       "  7,\n",
       "  4517,\n",
       "  6,\n",
       "  1,\n",
       "  88,\n",
       "  1685,\n",
       "  4,\n",
       "  1,\n",
       "  286,\n",
       "  4517,\n",
       "  105,\n",
       "  35,\n",
       "  227,\n",
       "  10,\n",
       "  420,\n",
       "  1,\n",
       "  1005,\n",
       "  493,\n",
       "  9,\n",
       "  57,\n",
       "  45,\n",
       "  33,\n",
       "  68,\n",
       "  3,\n",
       "  224,\n",
       "  706,\n",
       "  1,\n",
       "  362,\n",
       "  1898,\n",
       "  455,\n",
       "  149,\n",
       "  335,\n",
       "  148,\n",
       "  3,\n",
       "  19,\n",
       "  41,\n",
       "  3,\n",
       "  1702,\n",
       "  40,\n",
       "  1609,\n",
       "  27,\n",
       "  11,\n",
       "  354,\n",
       "  39,\n",
       "  1474,\n",
       "  31,\n",
       "  1,\n",
       "  4517,\n",
       "  5457]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Word index\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first10pairs = {k: word_index[k] for k in list(word_index)[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 3,\n",
       " 'and': 2,\n",
       " 'br': 7,\n",
       " 'i': 10,\n",
       " 'in': 8,\n",
       " 'is': 6,\n",
       " 'it': 9,\n",
       " 'of': 4,\n",
       " 'the': 1,\n",
       " 'to': 5}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first10pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Padding the sequence\n",
    "data = pad_sequences(sequences, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data into train and validation datasets\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 100)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download from: http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing tqdm to show a progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:19, 20574.79it/s]\n"
     ]
    }
   ],
   "source": [
    "glove_dir = './data/Chapter 6.1.2 - Using word embeddings/glove.6B/'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'), \n",
    "         encoding = 'utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], \n",
    "                       dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        # Words not found in the embedding index will be represented as zeros\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       [-0.071953  ,  0.23127   ,  0.023731  , ..., -0.71894997,\n",
       "         0.86894   ,  0.19539   ],\n",
       "       ...,\n",
       "       [ 0.13787   , -0.17727   , -0.62436002, ...,  0.35506001,\n",
       "         0.33443999,  0.14436001],\n",
       "       [-0.88968998,  0.55208999, -0.50498998, ..., -0.54351002,\n",
       "        -0.21874   ,  0.51186001],\n",
       "       [-0.17381001, -0.037609  ,  0.068837  , ..., -0.097167  ,\n",
       "         1.08840001,  0.22676   ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = max_words, \n",
    "                    output_dim = embedding_dim, \n",
    "                    input_length = maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 32, \n",
    "                activation = 'relu'))\n",
    "model.add(Dense(units = 1, \n",
    "                activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading pretrained word embeddings\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "# Freezing the layer\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
