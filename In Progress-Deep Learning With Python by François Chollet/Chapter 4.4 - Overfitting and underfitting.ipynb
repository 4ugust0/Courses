{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4.4 - Overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting IMDB data\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorizing the sequence\n",
    "def vectorize_sequences(sequences, dimension = 10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorizing the input datasets\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Changing types of the to float 32\n",
    "y_train = np.asarray(train_labels)\n",
    "y_train = y_train.astype('float32')\n",
    "\n",
    "y_test = np.asarray(test_labels)\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the original model\n",
    "def build_original_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 16, \n",
    "                    activation = 'relu', \n",
    "                    input_shape = (10000,)))\n",
    "    model.add(Dense(units = 16, \n",
    "                    activation = 'relu'))\n",
    "    model.add(Dense(units = 1, \n",
    "                    activation = 'sigmoid'))\n",
    "    model.compile(optimizer = 'rmsprop',\n",
    "                       loss = 'binary_crossentropy',\n",
    "                       metrics = ['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a small model\n",
    "def build_small_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 4, \n",
    "                    activation = 'relu', \n",
    "                    input_shape = (10000,)))\n",
    "    model.add(Dense(units = 4, \n",
    "                    activation = 'relu'))\n",
    "    model.add(Dense(units = 1, \n",
    "                    activation = 'sigmoid'))\n",
    "    model.compile(optimizer = 'rmsprop',\n",
    "                       loss = 'binary_crossentropy',\n",
    "                       metrics = ['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a big model\n",
    "def build_big_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 512, \n",
    "                    activation = 'relu', \n",
    "                    input_shape = (10000,)))\n",
    "    model.add(Dense(units = 512, \n",
    "                    activation = 'relu'))\n",
    "    model.add(Dense(units = 1, \n",
    "                    activation = 'sigmoid'))\n",
    "    model.compile(optimizer = 'rmsprop',\n",
    "                       loss = 'binary_crossentropy',\n",
    "                       metrics = ['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the original network\n",
    "original_network = build_original_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 7s - loss: 0.4617 - acc: 0.8187 - val_loss: 0.3468 - val_acc: 0.8789\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 5s - loss: 0.2687 - acc: 0.9069 - val_loss: 0.2910 - val_acc: 0.8880\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 7s - loss: 0.2046 - acc: 0.9288 - val_loss: 0.2809 - val_acc: 0.8888\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1725 - acc: 0.9381 - val_loss: 0.2963 - val_acc: 0.8833\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1459 - acc: 0.9484 - val_loss: 0.3102 - val_acc: 0.8799\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1296 - acc: 0.9558 - val_loss: 0.3287 - val_acc: 0.8779\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1154 - acc: 0.9599 - val_loss: 0.3579 - val_acc: 0.8738\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1014 - acc: 0.9663 - val_loss: 0.3723 - val_acc: 0.8716\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0908 - acc: 0.9698 - val_loss: 0.4124 - val_acc: 0.8670\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 3s - loss: 0.0818 - acc: 0.9735 - val_loss: 0.4678 - val_acc: 0.8527\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 3s - loss: 0.0730 - acc: 0.9768 - val_loss: 0.4728 - val_acc: 0.8625\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 3s - loss: 0.0647 - acc: 0.9796 - val_loss: 0.4802 - val_acc: 0.8619\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0558 - acc: 0.9829 - val_loss: 0.5112 - val_acc: 0.8592\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0472 - acc: 0.9862 - val_loss: 0.6020 - val_acc: 0.8540\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0435 - acc: 0.9872 - val_loss: 0.5830 - val_acc: 0.8531\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0372 - acc: 0.9892 - val_loss: 0.6242 - val_acc: 0.8564\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 3s - loss: 0.0306 - acc: 0.9918 - val_loss: 0.6533 - val_acc: 0.8554\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0288 - acc: 0.9916 - val_loss: 0.6984 - val_acc: 0.8532\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0218 - acc: 0.9949 - val_loss: 0.7242 - val_acc: 0.8526\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0200 - acc: 0.9954 - val_loss: 0.7537 - val_acc: 0.8506\n"
     ]
    }
   ],
   "source": [
    "# Training the original network\n",
    "original_network_history = original_network.fit(x_train, \n",
    "                     y_train,\n",
    "                     epochs = 20,\n",
    "                     batch_size = 512,\n",
    "                     validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_network = build_small_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 6s - loss: 0.5178 - acc: 0.7892 - val_loss: 0.4157 - val_acc: 0.8693\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.3292 - acc: 0.8989 - val_loss: 0.3240 - val_acc: 0.8853\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.2468 - acc: 0.9206 - val_loss: 0.2929 - val_acc: 0.8879\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.2030 - acc: 0.9337 - val_loss: 0.2824 - val_acc: 0.8887\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1766 - acc: 0.9416 - val_loss: 0.2887 - val_acc: 0.8856\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1563 - acc: 0.9482 - val_loss: 0.2910 - val_acc: 0.8839\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1418 - acc: 0.9534 - val_loss: 0.3010 - val_acc: 0.8819\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1286 - acc: 0.9572 - val_loss: 0.3127 - val_acc: 0.8783\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1182 - acc: 0.9622 - val_loss: 0.3303 - val_acc: 0.8760\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.1083 - acc: 0.9664 - val_loss: 0.3400 - val_acc: 0.8742\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 3s - loss: 0.0989 - acc: 0.9696 - val_loss: 0.3629 - val_acc: 0.8708\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0916 - acc: 0.9717 - val_loss: 0.3753 - val_acc: 0.8690\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0844 - acc: 0.9748 - val_loss: 0.3927 - val_acc: 0.8685\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0780 - acc: 0.9764 - val_loss: 0.4081 - val_acc: 0.8655\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0719 - acc: 0.9795 - val_loss: 0.4290 - val_acc: 0.8647\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0663 - acc: 0.9813 - val_loss: 0.4460 - val_acc: 0.8628\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0609 - acc: 0.9827 - val_loss: 0.4744 - val_acc: 0.8602\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0563 - acc: 0.9846 - val_loss: 0.5025 - val_acc: 0.8583\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0529 - acc: 0.9868 - val_loss: 0.5121 - val_acc: 0.8584\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 4s - loss: 0.0476 - acc: 0.9878 - val_loss: 0.5338 - val_acc: 0.8572\n"
     ]
    }
   ],
   "source": [
    "small_network_history = small_network.fit(x_train,  \n",
    "                                          y_train,\n",
    "                                          epochs = 20,\n",
    "                                          batch_size = 512,\n",
    "                                          validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 21)\n",
    "original_val_loss = original_network_history.history['val_loss']\n",
    "small_model_val_loss = small_network_history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAF3CAYAAAALu1cUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2034e866e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "# Plotting the validation loss of the original network\n",
    "# b+ is for \"blue cross\"\n",
    "plt.plot(epochs, \n",
    "         original_val_loss, \n",
    "         'b+', \n",
    "         label='Original model')\n",
    "# Plotting the validation loss of the small network\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, \n",
    "         small_model_val_loss, 'bo', label='Small model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller network overfits later than the bigger network. \n",
    "Let's investigate other scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
